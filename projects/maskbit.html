<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="description"
        content="MaskBit: Embedding-free Image Generation from Bit Tokens">
  <meta name="keywords" content="Image Tokenization, Image Generation">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>MaskBit: Embedding-free Image Generation from Bit Tokens</title>

  <script>
    window.dataLayer = window.dataLayer || [];

    function gtag() {
      dataLayer.push(arguments);
    }

    gtag('js', new Date());

    gtag('config', 'G-PYVRSFMDRL');
  </script>

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
        rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
        href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>
</head>
<body>

<nav class="navbar" role="navigation" aria-label="main navigation">
  <div class="navbar-brand">
    <a role="button" class="navbar-burger" aria-label="menu" aria-expanded="false">
      <span aria-hidden="true"></span>
      <span aria-hidden="true"></span>
      <span aria-hidden="true"></span>
    </a>
  </div>
  <div class="navbar-menu">
    <div class="navbar-start" style="flex-grow: 1; justify-content: center;">
      <a class="navbar-item" href="https://weber-mark.github.io/">
      <span class="icon">
          <i class="fas fa-home"></i>
      </span>
      </a>

      <div class="navbar-item has-dropdown is-hoverable">
        <a class="navbar-link">
          More Research
        </a>
        <div class="navbar-dropdown">
          <a class="navbar-item" href="https://weber-mark.github.io/projects/maskbit.html">
            MaskBit
          </a>
          <a class="navbar-item" href="https://yucornetto.github.io/projects/titok.html">
            TiTok
          </a>
          <a class="navbar-item" href="https://codalab.lisn.upsaclay.fr/competitions/2882">
            DynamicEarthNet
          </a>
          <a class="navbar-item" href="https://mehmetaygun.github.io/4DPLS.html">
            4D-PLS
          </a>
          <a class="navbar-item" href="https://github.com/google-research/deeplab2">
            DeepLab2
          </a>
        </div>
      </div>
    </div>

  </div>
</nav>


<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <h1 class="title is-3 publication-title">MaskBit: Embedding-free Image Generation via Bit Tokens</h1>
          <div class="is-size-5 publication-authors">
            <span class="author-block">
                <a href="https://weber-mark.github.io">Mark Weber</a><sup>1,2,3</sup>,</span>
            <span class="author-block">
                <a href="https://me.lj-y.com">Lijun Yu</a><sup>4</sup>,</span>
            <span class="author-block">
                <a href="https://yucornetto.github.io/">Qihang Yu</a><sup>1</sup>,</span>
            <span class="author-block">
              <a href="https://sites.google.com/view/xueqingdeng7/home">Xueqing Deng</a><sup>1</sup>,</span>
            <span class="author-block">
              <a href="https://xiaohuishen.github.io/">Xiaohui Shen</a><sup>1</sup>,</span>
            <span class="author-block">
              <a href="https://cvg.cit.tum.de/members/cremers">Daniel Cremers</a><sup>2,3</sup>,</span>
            <span class="author-block">
              <a href="http://liangchiehchen.com/">Liang-Chieh Chen</a><sup>1</sup></span>
           
          </div>

          <div class="is-size-5 publication-authors">
            <span class="author-block"><sup>1</sup>ByteDance, </span>
            <span class="author-block"><sup>2</sup>Technical University Munich, </span>
            <span class="author-block"><sup>3</sup>MCML, </span>
            <span class="author-block"><sup>4</sup>Carnegie Mellon University </span>
          </div>

          <div class="column has-text-centered">
            <div class="publication-links">
              <!-- PDF Link. -->
              <span class="link-block">
                <a href="https://arxiv.org/pdf/2409.16211"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fas fa-file-pdf"></i>
                  </span>
                  <span>Paper</span>
                </a>
              </span>
              <span class="link-block">
                <a href="https://arxiv.org/abs/2409.16211"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv</span>
                </a>
              </span>
              <!-- Video Link. -->
              <!-- <span class="link-block">
                <a href="https://www.youtube.com/watch?v=MrKrnHhk8IA"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-youtube"></i>
                  </span>
                  <span>Video</span>
                </a>
              </span> -->
              <!-- Code Link. -->
              <span class="link-block">
                <a href="TODO"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-github"></i>
                  </span>
                  <span>Code (coming soon)</span>
                  </a>
              </span>

<!--               <span class="link-block">
                <a href="https://huggingface.co/fun-research/TiTok"
                   class="external-link button is-normal is-rounded is-dark">

                  <span>ðŸ¤— HuggingFace Model</span>
                  </a>
              </span>
              <span class="link-block">
                <a href="https://huggingface.co/spaces/fun-research/TiTok"
                   class="external-link button is-normal is-rounded is-dark">

                  <span>ðŸ¤— HuggingFace Demo</span>
              </a>
              </span> -->
            </div>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>

<section class="hero teaser has-carousel">
  <div class="container is-max-desktop">
      <div class="hero-body">
          <div id="carousel-demo" class="teaser-carousel" data-autoplay="true">
              <div class="carousel-item">
                <img src="./static/images/teaser1.png" alt="Teaser image 1" class="teaser"/>
              </div>
              <div class="carousel-item">
                <img src="./static/images/teaser2.png" alt="Teaser image 2" class="teaser"/>
              </div>
              <div class="carousel-item">
                <img src="./static/images/teaser3.png" alt="Teaser image 3" class="teaser"/>
              </div>
              <div class="carousel-item">
                <img src="./static/images/teaser4.png" alt="Teaser image 4" class="teaser"/>
              </div>
          </div>
          <h2 class="subtitle has-text-centered">
              <b>Generated images by our proposed MaskBit.</b>
              We showcase samples from MaskBit trained on ImageNet at 256<span> &#215;</span> 256 resolution.
          </h2>
      </div>
  </div>
</section>

<script>
  bulmaCarousel.attach('#carousel-demo', {
    slidesToScroll: 1,
    slidesToShow: 1,
    autoplay: true,
    infinite: true,
    autoplaySpeed: 10000,
  });
</script>


<section class="hero is-light is-big", style="margin-top: -35px">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-five-fifths">
        <br>
        <br>
        <h2 class="title is-3">ðŸ”¥ Highlights</h2>
      </div>
    </div>

    <div class="columns is-centered">
      <div class="column is-five-fifths">
        <p style="font-size: 20px; margin-bottom: 10px;">
        1. We study the key ingredients of recent closed-source VQGAN tokenizers and develop a <span style="color:rgba(14, 122, 41, 0.904) " ><b>publicly available, reproducible, and high-performing VQGAN model</b></span>, called VQGAN+, 
        achieving a significant <span style="color: rgb(199, 9, 9)"><b>improvement of 6.28 rFID</b></span> over the original VQGAN developed three years ago.
        </p>
        <p style="font-size: 20px; margin-bottom: 10px;">
        2. Building on our improved tokenizer framework, we leverage modern Lookup-Free Quantization (LFQ). 
        We analyze the latent representation and observe that <span style="color: rgb(131, 102, 7)"><b>embedding-free bit token representation exhibits highly structured semantics</b></span>.
        </p>
        <p style="font-size: 20px;">
        3. Motivated by these discoveries, we develop a novel embedding-free generation framework, <b>MaskBit</b>, 
        which builds on top of the bit tokens and achieves <span style="color: rgb(4, 23, 107)"><b>state-of-the-art performance on the ImageNet 256<span>&#215;</span>256 class-conditional image generation benchmark</b></span>.
        </p>
        <br><br>
      </div>
    </div>
  </div>
</section>


<section class="section">
  <div class="container is-max-desktop">
    <!-- Abstract. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
            Masked transformer models for class-conditional image generation have become a compelling alternative to diffusion models. Typically comprising two stages - an initial VQGAN model for transitioning between latent space and image space, and a subsequent Transformer model for image generation within latent space - these frameworks offer promising avenues for image synthesis.
            In this study, we present two primary contributions: Firstly, an empirical and systematic examination of VQGANs, leading to a modernized VQGAN.
            Secondly, a novel embedding-free generation network operating directly on bit tokens -- a binary quantized representation of tokens with rich semantics.
            The first contribution furnishes a transparent, reproducible, and high-performing VQGAN model, enhancing accessibility and matching the performance of current state-of-the-art methods while revealing previously undisclosed details.
            The second contribution demonstrates that embedding-free image generation using bit tokens achieves a new state-of-the-art FID of 1.52 on the ImageNet 256<span>&#215;</span>256 benchmark, with a compact generator model of mere 305M parameters.
          </p>
        </div>
      </div>
    </div>
  </div>
</section>
    <!--/ Abstract. -->




<section class="section">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-full-width">
        <h2 class="title is-3"> MaskBit Framework Overview</h2>
      </div>
    </div>
    <div class="columns is-centered ">
      <div class="column is-full-width">
        <div class="column is-centered ">
          <img src="./static/images/arch_maskbit_taming_small.png"
                    class="framework-image"
                    alt="framework overview image."/>
          <h2 class="subtitle has-text-centered">
            <b>High-level overview of the architecture and comparison.</b>
            Our training framework comprises two stages for image generation. 
            In Stage-I, an encoder-decoder network compresses images into a latent representation and 
            decodes them back. Stage-II masks the tokens, feeds them into a transformer and predicts the masked tokens. 
            Most prior art uses VQGAN-based methods (top) that learn independent embedding tables in both stages. 
            In VQGAN-based methods, only indices of embedding tables are shared across stages, but not the embeddings. 
            In MaskBit, however, neither Stage-I nor Stage-II utilizes embedding tables. The Stage-I predicts bit tokens by 
            using binary quantization on the encoder output directly. The Stage-II partitions the shared bit tokens into groups (e.g., 2 groups),
             masks and feeds them into a transformer, and predicts the masked bit tokens.
          </h2>
        </div>
      </div>
    </div>
  </div>
</section>



<section class="section">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-full-width">
        <h2 class="title is-3">Demystifying VQGAN training</h2>
      </div>
    </div>
    <div class="columns is-centered ">
      <div class="column is-full-width">
        <div class="column is-centered ">
          <video id="demystifying" autoplay muted loop playsinline height="100%">
            <source src="./static/images/demystifying_vqgan_1sec.mp4" type="video/mp4">
          </video>
          <h2 class="subtitle has-text-centered">
            <b>Roadmap to build a modern VQGAN+.</b> 
            This overview summarizes the performance gains achieved by each proposed change to the architecture and training recipe. 
            The reconstruction FID (rFID) is computed against the validation split of ImageNet at a resolution of 256. 
            The popular and open-source <a href="https://github.com/CompVis/taming-transformers">Taming-VQGAN</a> serves as the baseline and starting point.
          </h2>
    </div>
  </div>
</div>
</div>
</section>

<section class="section">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-full-width">
        <h2 class="title is-3">Bit tokens are structured semantic representations</h2>
      </div>
    </div>
    <div class="columns is-centered ">
      <div class="column is-full-width">
        <div class="column is-centered ">
          <video id="bit-tokens" autoplay muted loop playsinline height="100%">
            <source src="./static/images/bit_tokens_flipping.mp4" type="video/mp4">
          </video>
          <h2 class="subtitle has-text-centered">
            <!-- <b>Bit tokens exhibit structured semantic representations.</b>  -->
            We visualize a robustness test involving bit flipping. 
            Specifically, we encode images into bit tokens, where each token is represented by 12 bits in this example. 
            We then flip the i-th bit for all the bit tokens and reconstruct the images as usual. 
            Interestingly, the reconstructed images from these bit-flipped tokens remain <b>semantically consistent</b> to the original image, exhibiting only minor visual modifications such as changes in texture, exposure, smoothness, color palette, or painterly quality.
          </h2>
    </div>
  </div>
</div>
</div>
</section>

<section class="section">
  <div class="container is-max-widescreen">
    <div class="columns is-centered has-text-centered">
      <div class="column is-full-width">
        <h2 class="title is-3">Main Experiment Results</h2>
      </div>
    </div>
    <div class="columns is-centered ">
      <div class="column is-four-fifths">
        <img src="./static/images/results_256.png"
                  class="results256-image"
                  alt="results256 table."/>
        <img src="./static/images/model_comp.png"
                  class="modelcomp-image"
                  alt="model comparison performance table."/>
      </div>
    </div>
  </div>
</section>



<section class="section" id="BibTeX">
  <div class="container is-max-desktop content">
    <h2 class="title">BibTeX</h2>
    <pre><code>@article{weber2024maskbit,
  author    = {Mark Weber and Lijun Yu and Qihang Yu and Xueqing Deng and Xiaohui Shen and Daniel Cremers and Liang-Chieh Chen},
  title     = {MaskBit: Embedding-free Image Generation via Bit Tokens},
  journal   = {arXiv:2409.16211},
  year      = {2024}
}</code></pre>
  </div>
</section>


<footer class="footer">
  <div class="container">
    <div class="content has-text-centered">
      <!-- <a class="icon-link"
         href="https://drive.google.com/file/d/1QgiG-X15kUGUMikNBg5MSROMgHvc-GhG/view?usp=drive_link">
        <i class="fas fa-file-pdf"></i>
      </a>
      <a class="icon-link" href="https://github.com/keunhong" class="external-link" disabled>
        <i class="fab fa-github"></i>
      </a> -->
    </div>
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">
          <p>
            This website is licensed under a <a rel="license"
                                                href="http://creativecommons.org/licenses/by-sa/4.0/">Creative
            Commons Attribution-ShareAlike 4.0 International License</a>.
          </p>
          <p>
            This means you are free to borrow the <a
              href="https://github.com/nerfies/nerfies.github.io">source code</a> of this website,
            we just ask that you link back to this page in the footer.
            Please remember to remove the analytics code included in the header of the website which
            you do not want on your website.
          </p>
        </div>
      </div>
    </div>
  </div>
</footer>

</body>
</html>
